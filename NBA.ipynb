{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start:\n",
    "This notebook shows how to execute YOLOv7 to detect loading bay door positions in video. The data for this project\n",
    "was annotated using RoboFlow. \n",
    "\n",
    "The data can be accessed here: https://app.roboflow.com/james-skelton/ballhandler-basketball/overview\n",
    "\n",
    "and you can download it with:\n",
    "\n",
    "> $ curl -L \"https://app.roboflow.com/ds/yjvwwIdZlU?key=I3Dz8Y1jHy\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "\n",
    "\n",
    "Miscellaneous notes:\n",
    "- Go to \"Train\" to train a model from scratch, \"Test\" to assess the quality of a trained model, and \"Detect\" to run detection on a sample. \n",
    "- To access the training data & pretrained model for this repo, run the following cell. You will then need to navigate to the \"Helpers\" section, and follow the instructions there to set up your code for YOLOv7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-26T00:43:59.314893Z",
     "iopub.status.busy": "2022-07-26T00:43:59.314633Z",
     "iopub.status.idle": "2022-07-26T00:44:03.893149Z",
     "shell.execute_reply": "2022-07-26T00:44:03.892621Z",
     "shell.execute_reply.started": "2022-07-26T00:43:59.314873Z"
    }
   },
   "outputs": [],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/yjvwwIdZlU?key=I3Dz8Y1jHy\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "! pip install gdown\n",
    "! gdown 164x37XUfwdo0NK8yHWUe69VnKslemvKn\n",
    "! gdown 1C7IKcnlhfyUIG8d5SoiiY026Z4BCYRCx\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T23:08:39.656567Z",
     "iopub.status.busy": "2022-07-27T23:08:39.655641Z",
     "iopub.status.idle": "2022-07-27T23:15:25.599543Z",
     "shell.execute_reply": "2022-07-27T23:15:25.597490Z",
     "shell.execute_reply.started": "2022-07-27T23:08:39.656386Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install torchvision==0.11.3+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "To set up your RoboFlow annotated data for YOLO, we've provided some helper functions to quickly clean up the filenames. \n",
    "Simply run all the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T18:30:06.763053Z",
     "iopub.status.busy": "2022-07-22T18:30:06.762346Z",
     "iopub.status.idle": "2022-07-22T18:30:09.497100Z",
     "shell.execute_reply": "2022-07-22T18:30:09.494552Z",
     "shell.execute_reply.started": "2022-07-22T18:30:06.762990Z"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir v-test\n",
    "! mv train/ v-test/\n",
    "! mv test/ v-test/\n",
    "! mv valid/ v-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# remove roboflow extra junk\n",
    "\n",
    "count = 0\n",
    "for i in sorted(os.listdir('v-test/train/labels')):\n",
    "    if count >=3:\n",
    "        count = 0\n",
    "    count += 1\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    dict1 = {1:'a', 2:'b', 3:'c'}\n",
    "    source = 'v-test/train/labels/'+i\n",
    "    dest = 'v-test/train/labels/'+j[0]+dict1[count]+'.txt'\n",
    "    os.rename(source, dest)\n",
    "    \n",
    "count = 0\n",
    "for i in sorted(os.listdir('v-test/train/images')):\n",
    "    if count >=3:\n",
    "        count = 0\n",
    "    count += 1\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    dict1 = {1:'a', 2:'b', 3:'c'}\n",
    "    source = 'v-test/train/images/'+i\n",
    "    dest = 'v-test/train/images/'+j[0]+dict1[count]+'.jpg'\n",
    "    os.rename(source, dest)\n",
    "    \n",
    "for i in sorted(os.listdir('v-test/valid/labels')):\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    source = 'v-test/valid/labels/'+i\n",
    "    dest = 'v-test/valid/labels/'+j[0]+'.txt'\n",
    "    os.rename(source, dest)\n",
    "    \n",
    "for i in sorted(os.listdir('v-test/valid/images')):\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    source = 'v-test/valid/images/'+i\n",
    "    dest = 'v-test/valid/images/'+j[0]+'.jpg'\n",
    "    os.rename(source, dest)\n",
    "for i in sorted(os.listdir('v-test/test/labels')):\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    source = 'v-test/test/labels/'+i\n",
    "    dest = 'v-test/test/labels/'+j[0]+'.txt'\n",
    "    os.rename(source, dest)\n",
    "    \n",
    "for i in sorted(os.listdir('v-test/test/images')):\n",
    "    if i[0] == '.':\n",
    "        continue\n",
    "    j = i.split('_')\n",
    "    source = 'v-test/test/images/'+i\n",
    "    dest = 'v-test/test/images/'+j[0]+'.jpg'\n",
    "    os.rename(source, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "\n",
    "This section shows how to fine tune a model for a custom dataset.\n",
    "\n",
    "### Training instructions & tips\n",
    "- If you need to change the locations of your training/validation/test images, then be sure to go to custom.yaml in the \"data\" folder, and change the path locations. \n",
    "- also in custom.yaml, you can set and label the number of labels you want to be able to detect with your model\n",
    "- If you are on a distributed machine, use the second train command in the cell below. Be sure to change \"nproc_per_node\" to accurately reflect the number of GPUs on your device. \n",
    "- use the hyp.scratch.custom.yaml file to change hyperparameters for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T23:16:06.579020Z",
     "iopub.status.busy": "2022-07-27T23:16:06.576603Z",
     "iopub.status.idle": "2022-07-27T23:23:52.195050Z",
     "shell.execute_reply": "2022-07-27T23:23:52.192681Z",
     "shell.execute_reply.started": "2022-07-27T23:16:06.578949Z"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py --workers 8 --device 0 --batch-size 2 --data data/coco.yaml --img 640 360 --cfg cfg/training/yolov7x.yaml --weights yolov7_training.pt --name yolov7-ballhandler --hyp data/hyp.scratch.custom.yaml --epochs 50\n",
    "\n",
    "# !python -m torch.distributed.launch --nproc_per_node 2 --master_port 9527 train.py --workers 16 --device 0,1 --sync-bn --batch-size 8 --data data/coco.yaml --img 1280 720 --cfg cfg/training/yolov7.yaml --weights yolov7_training.pt --name yolov7-ballhandler --hyp data/hyp.scratch.custom.yaml --epochs 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect\n",
    "\n",
    "Use the following cell to run detection on a submitted image. \n",
    "\n",
    "- Change image or video being detected on using --source tag\n",
    "- img size X dimension must be correct for this to run. no Y needed\n",
    "- if you want to do detection on anything other than the test set, you will need to upload the video to the platform using a standard file upload in the top left corner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T22:14:03.047176Z",
     "iopub.status.busy": "2022-08-04T22:14:03.046117Z",
     "iopub.status.idle": "2022-08-04T22:27:36.242220Z",
     "shell.execute_reply": "2022-08-04T22:27:36.241362Z",
     "shell.execute_reply.started": "2022-08-04T22:14:03.047143Z"
    }
   },
   "outputs": [],
   "source": [
    "#your model\n",
    "!python detect.py --weights runs/train/yolov7-ballhandler/weights/best.pt --conf 0.25 --img-size 640 --source \"testvid-nba.mp4\" --name test\n",
    "#pretrained\n",
    "!python detect.py --weights best_basketball.pt --conf 0.25 --img-size 640 --source \"testvid-nba.mp4\" --name test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T23:10:51.251252Z",
     "iopub.status.busy": "2022-08-04T23:10:51.250406Z",
     "iopub.status.idle": "2022-08-04T23:11:16.871974Z",
     "shell.execute_reply": "2022-08-04T23:11:16.871240Z",
     "shell.execute_reply.started": "2022-08-04T23:10:51.251219Z"
    }
   },
   "outputs": [],
   "source": [
    "# your model\n",
    "!python test.py --data data/test.yaml --img 640 --batch 16 --conf 0.001 --iou 0.65 --device 0 --weights runs/train/yolov7-ballhandler/weights/best.pt --name yolov7_ballhandler_testing\n",
    "\n",
    "#pretrained\n",
    "!python test.py --data data/test.yaml --img 640 --batch 16 --conf 0.001 --iou 0.65 --device 0 --weights best_basketball.pt --name yolov7_ballhandler_testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
